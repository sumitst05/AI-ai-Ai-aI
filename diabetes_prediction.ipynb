{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Machine Learning Algorithm"
      ],
      "metadata": {
        "id": "lP4A7AxUPZmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using multi layer perceptron | Supervised Learning\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "\n",
        "# Extract features and target variable (Labeling the dataset)\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the feature values\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create the MLP model\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUrpeGqDO3rA",
        "outputId": "8ef628a5-f82d-4f21-e63a-d53142ecbade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6883116883116883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning Algorithm"
      ],
      "metadata": {
        "id": "xdjln11TPfiq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_PquUxMOnR4",
        "outputId": "563bbec6-cc4e-498d-8115-5f047c484ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 1s 10ms/step - loss: 0.6364 - accuracy: 0.6599 - val_loss: 0.6073 - val_accuracy: 0.6667\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.5470 - accuracy: 0.7088 - val_loss: 0.5539 - val_accuracy: 0.7154\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7800 - val_loss: 0.5118 - val_accuracy: 0.7561\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7902 - val_loss: 0.4861 - val_accuracy: 0.7642\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8004 - val_loss: 0.4755 - val_accuracy: 0.7724\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.8004 - val_loss: 0.4682 - val_accuracy: 0.7724\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7963 - val_loss: 0.4676 - val_accuracy: 0.7805\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8045 - val_loss: 0.4612 - val_accuracy: 0.7561\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8065 - val_loss: 0.4676 - val_accuracy: 0.7724\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8065 - val_loss: 0.4664 - val_accuracy: 0.7642\n",
            "5/5 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.7597402597402597\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (replace 'path_to_dataset.csv' with the actual path)\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "\n",
        "# Extract features and target variable\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the feature values\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ]
    }
  ]
}